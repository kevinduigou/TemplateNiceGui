# {{ project_name }}

{{ project_description }}

## Architecture

This project follows clean architecture principles with clear separation of concerns:

- **Domain Layer** (`src/{{ project_slug }}/domain/`): Core business logic, immutable and pure
- **Application Layer** (`src/{{ project_slug }}/application/`): Use cases and orchestration
- **Infrastructure Layer** (`src/{{ project_slug }}/infrastructure/`): External integrations (DB, APIs, I/O)
- **Interface Layer** (`src/{{ project_slug }}/interface/`): NiceGUI frontend

## Prerequisites

- Python {{ python_version }}+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip
{%- if use_docker %}
- Docker and Docker Compose (optional, for containerized deployment)
{%- endif %}
{%- if use_oauth %}
- OAuth credentials:
{%- if oauth_providers in ['google', 'both'] %}
  - Google: [Get credentials](https://console.cloud.google.com/apis/credentials)
{%- endif %}
{%- if oauth_providers in ['twitter', 'both'] %}
  - Twitter: [Get credentials](https://developer.twitter.com/en/portal/dashboard)
{%- endif %}
{%- endif %}

## Installation

### Using uv (recommended)

```bash
# Install dependencies
uv sync

# Install with dev dependencies
uv sync --all-extras
```

### Using pip

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -e ".[dev]"
```

{%- if use_oauth %}

## OAuth Configuration

1. Copy the environment file template:
```bash
cp .env.example .env
```

2. Fill in your OAuth credentials in `.env`:
{%- if oauth_providers in ['google', 'both'] %}

### Google OAuth Setup
- Go to [Google Cloud Console](https://console.cloud.google.com/apis/credentials)
- Create a new OAuth 2.0 Client ID
- Add `http://localhost:8080` to authorized JavaScript origins
- Add `http://localhost:8080/auth/google/callback` to authorized redirect URIs
- Copy the Client ID and Client Secret to your `.env` file
{%- endif %}
{%- if oauth_providers in ['twitter', 'both'] %}

### Twitter OAuth Setup
- Go to [Twitter Developer Portal](https://developer.twitter.com/en/portal/dashboard)
- Create a new app or use an existing one
- Enable OAuth 2.0
- Add `http://localhost:8080/auth/twitter/callback` to callback URLs
- Copy the Client ID and Client Secret to your `.env` file
{%- endif %}

3. Generate a random secret for session management:
```bash
python -c "import secrets; print(secrets.token_urlsafe(32))"
```
Add this to `STORAGE_SECRET` in your `.env` file.

{%- endif %}

## Running the Application

```bash
# Using uv
uv run python -m {{ project_slug }}

# Using pip
python -m {{ project_slug }}
```

The application will be available at http://localhost:8080
{%- if use_oauth %}

**Note:** When using OAuth, you must access the application via `http://localhost:8080` (not `127.0.0.1:8080`) for OAuth callbacks to work correctly.
{%- endif %}

{%- if use_docker %}

## Docker Deployment

### Production Deployment

```bash
# Build and run with Docker Compose
docker-compose up --build

# Run in detached mode
docker-compose up -d

# Stop services
docker-compose down
```

The application will be available at http://localhost:8080

### VS Code Dev Container

This project includes a complete VS Code Dev Container configuration for a consistent development environment.

**Features:**
- Pre-configured Python environment with all dependencies
- Automatic installation of recommended VS Code extensions
- Ruff, mypy, and pytest pre-configured
- Format on save enabled
{%- if async_task_backend == 'redis_rq' %}
- Redis service automatically started
{%- endif %}

**To use:**
1. Install [Docker](https://www.docker.com/products/docker-desktop) and [VS Code](https://code.visualstudio.com/)
2. Install the [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)
3. Open the project in VS Code
4. Click "Reopen in Container" when prompted (or use Command Palette: "Dev Containers: Reopen in Container")

The dev container uses the `dev-base` stage from the Dockerfile, which includes:
- All development tools (vim, nano, build-essential)
- Non-root user (vscode) with sudo access
- Automatic dependency installation via `uv sync --all-extras`

### Docker Architecture

The Dockerfile uses multi-stage builds for efficiency:

- **base**: Common base with Python and uv
- **dev-base**: Development environment (used by devcontainer)
- **dependencies**: Installs Python packages
- **production**: Minimal production image
{%- if async_task_backend == 'redis_rq' %}
- **worker**: RQ worker for background tasks
{%- endif %}

This approach:
- Shares the base image between development and production
- Keeps production images small
- Enables fast rebuilds during development
{%- endif %}

## Development

### Code Quality

Run all quality checks before committing:

```bash
# Run tests
uv run pytest

# Check code quality
uv run ruff check

# Type checking
uv run mypy src/{{ project_slug }}

# Format code (do this last)
uv run ruff format
```

### Running Tests

```bash
# Unit tests
uv run pytest tests/unit/

# Integration tests
uv run behave

# With coverage
uv run pytest --cov={{ project_slug }} --cov-report=html
```

## Project Structure

```
{{ project_slug }}/
├── src/
│   └── {{ project_slug }}/
│       ├── domain/              # Core business logic
│       │   ├── entities/        # Mutable domain objects
│       │   ├── value_objects/   # Immutable domain objects
│       │   └── events/          # Domain events
│       ├── application/         # Use cases
│       │   ├── commands/        # State-changing operations
│       │   ├── queries/         # Read-only operations
{%- if async_task_backend == 'redis_rq' %}
│       │   ├── commands_async/  # Long-running commands (RQ)
│       │   └── queries_async/   # Long-running queries (RQ)
{%- endif %}
│       ├── infrastructure/      # External integrations
{%- if use_sqlite_db %}
│       │   ├── cache_db/        # SQLite database (SQLAlchemy)
{%- endif %}
│       │   ├── database/        # Database access
│       │   └── external_apis/   # External API clients
│       └── interface/           # NiceGUI UI
│           ├── pages/           # UI pages
│           └── components/      # Reusable UI components
├── tests/
│   ├── unit/                    # Unit tests
│   └── integration/             # Integration tests
├── features/                    # BDD tests (behave)
{%- if use_docker %}
├── docker/                      # Docker configuration
{%- endif %}
├── infra/
│   └── terraform/               # Terraform for GKE, Artifact Registry, Redis, CI IAM
├── k8s/                         # Kubernetes manifests for FastAPI, RQ worker, ingress
├── .github/workflows/           # CI/CD pipelines
└── pyproject.toml              # Project configuration
```

## GCP/GKE Deployment Starter Kit

- **Terraform** (`infra/terraform/`): Provisions a regional GKE cluster with an autoscaled node pool, Artifact Registry, a Redis Helm release (Bitnami), and a CI service account with the required roles.
- **Kubernetes manifests** (`k8s/`): Deployments for the FastAPI app and optional RQ worker, HPAs, optional KEDA ScaledObject, ingress, and namespace manifest.
- **GitHub Actions pipeline** (`.github/workflows/deploy-gke.yml`): Builds and pushes the app image to Artifact Registry, fetches GKE credentials, injects the commit SHA as the image tag, and applies the manifests.

### Bootstrap flow

1. Run `terraform init` and `terraform apply` inside `infra/terraform` (set `project_id`, `region`, and other variables).
2. Create GitHub secrets: `GCP_PROJECT_ID`, `GCP_REGION`, `GKE_CLUSTER`, `GCP_SA_KEY` (JSON), and `GCP_ARTIFACT_IMAGE` (e.g., `europe-west1-docker.pkg.dev/PROJECT/REPO/app`).
3. Update `k8s/ingress.yaml` and the image registry path placeholders in the deployment manifests as needed.
4. Push to `main` to trigger the deployment workflow.

## Features

{%- if use_sqlite_db %}

### SQLite Database Support

This project includes SQLite database support with SQLAlchemy ORM:

- **Location**: `src/{{ project_slug }}/infrastructure/cache_db/`
- **Features**:
  - Automatic table creation on initialization
  - Result-based error handling (no exceptions)
  - Type-safe operations with mypy support
  - Example models and repository included

**Quick Start:**

```python
from {{ project_slug }}.infrastructure.cache_db import DBRepository

# Initialize repository (creates database automatically)
db_repo = DBRepository()  # Default: sqlite:///data/{{ project_slug }}.db

# Save a record
result = db_repo.save_example("id-1", "Example Name", "Description")
```

See `src/{{ project_slug }}/infrastructure/cache_db/README.md` for detailed documentation.

{%- endif %}
{%- if async_task_backend == 'redis_rq' %}

### Background Task Processing

Long-running tasks are handled by RQ workers:

- **Commands**: `src/{{ project_slug }}/application/commands_async/`
- **Queries**: `src/{{ project_slug }}/application/queries_async/`
- **Worker**: Configured in `docker/Dockerfile.worker`

{%- endif %}
{%- if use_oauth %}

### OAuth Authentication

OAuth 2.0 authentication support for:
{%- if oauth_providers in ['google', 'both'] %}
- Google
{%- endif %}
{%- if oauth_providers in ['twitter', 'both'] %}
- Twitter
{%- endif %}

See OAuth Configuration section above for setup instructions.

{%- endif %}

## Design Principles

### Immutability First
- All function parameters are immutable by default
- Use `@dataclass(frozen=True)` for value objects
- Entities are mutable, but modifications are explicit

### Rust-Style Error Handling
- No exceptions in domain/application layers
- Use `Result[T, E]` from the `result` library
- Only infrastructure layer uses try/except for I/O

### Explicit Over Implicit
- No magic numbers or dynamic behavior
- Clear, descriptive variable and function names
- No single-letter variables

## Contributing

1. Follow the architecture guidelines in `.clinerules/Agents.md`
2. Write tests for new features
3. Run quality checks before committing
4. Keep domain layer pure (no external dependencies)

## License

[Your License Here]
