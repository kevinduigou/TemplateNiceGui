"""GCP Pub/Sub Worker for processing async tasks.

This worker subscribes to a Pub/Sub topic and processes incoming task messages.
It updates job status and metadata in Firestore throughout the execution.
"""

import importlib
import json
import logging
import signal
import sys
from typing import Any

from google.cloud import firestore, pubsub_v1

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


class PubSubWorker:
    """Worker that processes tasks from GCP Pub/Sub."""

    def __init__(
        self,
        project_id: str,
        subscription_name: str = "async-tasks-sub",
        firestore_collection: str = "job_metadata",
    ):
        """Initialize the Pub/Sub worker.

        Args:
            project_id: GCP project ID
            subscription_name: Pub/Sub subscription name
            firestore_collection: Firestore collection for job metadata
        """
        self._project_id = project_id
        self._subscription_path = f"projects/{project_id}/subscriptions/{subscription_name}"
        self._firestore_collection = firestore_collection
        
        self._subscriber = pubsub_v1.SubscriberClient()
        self._firestore_client = firestore.Client(project=project_id)
        self._running = True
        
        # Set up signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)

    def _signal_handler(self, signum: int, frame: Any) -> None:
        """Handle shutdown signals.

        Args:
            signum: Signal number
            frame: Current stack frame
        """
        logger.info(f"Received signal {signum}, shutting down gracefully...")
        self._running = False

    def _update_job_status(
        self,
        job_id: str,
        status: str,
        **additional_fields: Any
    ) -> None:
        """Update job status in Firestore.

        Args:
            job_id: Job ID to update
            status: New status
            **additional_fields: Additional fields to update
        """
        try:
            job_ref = self._firestore_client.collection(self._firestore_collection).document(job_id)
            update_data = {"status": status, **additional_fields}
            job_ref.update(update_data)
        except Exception as e:
            logger.error(f"Failed to update job status for {job_id}: {e}")

    def _get_job_metadata(self, job_id: str) -> dict[str, Any]:
        """Get current job metadata from Firestore.

        Args:
            job_id: Job ID to retrieve

        Returns:
            Job metadata dictionary
        """
        try:
            job_ref = self._firestore_client.collection(self._firestore_collection).document(job_id)
            job_doc = job_ref.get()
            if job_doc.exists:
                return job_doc.to_dict() or {}
            return {}
        except Exception as e:
            logger.error(f"Failed to get job metadata for {job_id}: {e}")
            return {}

    def _process_message(self, message: pubsub_v1.subscriber.message.Message) -> None:
        """Process a single Pub/Sub message.

        Args:
            message: Pub/Sub message to process
        """
        try:
            # Parse message data
            message_data = json.loads(message.data.decode("utf-8"))
            job_id = message_data["job_id"]
            function_path = message_data["function"]
            args = message_data.get("args", [])
            kwargs = message_data.get("kwargs", {})
            
            logger.info(f"Processing job {job_id}: {function_path}")
            
            # Check if job was canceled
            job_data = self._get_job_metadata(job_id)
            if job_data.get("status") == "canceled":
                logger.info(f"Job {job_id} was canceled, skipping execution")
                message.ack()
                return
            
            # Update status to running
            self._update_job_status(
                job_id,
                "running",
                started_at=firestore.SERVER_TIMESTAMP,
            )
            
            # Import and execute the function
            module_path, function_name = function_path.rsplit(".", 1)
            module = importlib.import_module(module_path)
            func = getattr(module, function_name)
            
            # Execute the function
            result = func(*args, **kwargs)
            
            # Update status to finished
            self._update_job_status(
                job_id,
                "finished",
                finished_at=firestore.SERVER_TIMESTAMP,
                result=str(result),  # Convert result to string for Firestore
            )
            
            logger.info(f"Job {job_id} completed successfully")
            message.ack()
            
        except Exception as e:
            logger.error(f"Error processing message: {e}", exc_info=True)
            
            # Try to update job status to failed
            try:
                message_data = json.loads(message.data.decode("utf-8"))
                job_id = message_data.get("job_id")
                if job_id:
                    self._update_job_status(
                        job_id,
                        "failed",
                        failed_at=firestore.SERVER_TIMESTAMP,
                        error=str(e),
                    )
            except Exception as update_error:
                logger.error(f"Failed to update job status: {update_error}")
            
            # Nack the message so it can be retried
            message.nack()

    def start(self) -> None:
        """Start the worker and begin processing messages."""
        logger.info(f"Starting Pub/Sub worker for subscription: {self._subscription_path}")
        
        # Create streaming pull future
        streaming_pull_future = self._subscriber.subscribe(
            self._subscription_path,
            callback=self._process_message,
        )
        
        logger.info("Worker started, waiting for messages...")
        
        try:
            # Keep the worker running
            while self._running:
                streaming_pull_future.result(timeout=1.0)
        except TimeoutError:
            # Timeout is expected, continue running
            pass
        except Exception as e:
            logger.error(f"Error in worker: {e}", exc_info=True)
        finally:
            # Cancel the subscription
            streaming_pull_future.cancel()
            streaming_pull_future.result()
            logger.info("Worker stopped")


def main() -> None:
    """Main entry point for the Pub/Sub worker."""
    import os
    
    # Get configuration from environment variables
    project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")
    if not project_id:
        logger.error("GOOGLE_CLOUD_PROJECT environment variable not set")
        sys.exit(1)
    
    subscription_name = os.environ.get("PUBSUB_SUBSCRIPTION", "async-tasks-sub")
    firestore_collection = os.environ.get("FIRESTORE_COLLECTION", "job_metadata")
    
    # Create and start worker
    worker = PubSubWorker(
        project_id=project_id,
        subscription_name=subscription_name,
        firestore_collection=firestore_collection,
    )
    
    worker.start()


if __name__ == "__main__":
    main()
